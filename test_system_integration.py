#!/usr/bin/env python3
"""
FXã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ

Week 1 Day 1-2ã®å®Ÿè£…å®Œäº†ç¢ºèªã¨ãƒ¡ãƒ¢ãƒ­ã‚¸ãƒƒã‚¯çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append('./src')

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ä½œæˆã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from indicators.base_indicators import BaseIndicators, PerformanceTracker
from utils.database import DatabaseManager
from utils.oanda_client import OandaClient
from operation_logic.key_concepts import OperationLogicEngine, Direction, TimeFrame

def test_indicators_calculation():
    """åŸºæœ¬æŒ‡æ¨™è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§® åŸºæœ¬æŒ‡æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    dates = pd.date_range('2024-01-01', periods=100, freq='1min')
    sample_data = pd.DataFrame({
        'open': np.random.randn(100).cumsum() + 150,
        'high': np.random.randn(100).cumsum() + 151,
        'low': np.random.randn(100).cumsum() + 149,
        'close': np.random.randn(100).cumsum() + 150
    }, index=dates)
    
    indicators = BaseIndicators()
    
    # å¹³å‡è¶³è¨ˆç®—ãƒ†ã‚¹ãƒˆ
    ha_result = indicators.calculate_heikin_ashi(sample_data)
    assert 'ha_open' in ha_result.columns, "å¹³å‡è¶³è¨ˆç®—å¤±æ•—"
    assert 'ha_direction' in ha_result.columns, "å¹³å‡è¶³æ–¹å‘è¨ˆç®—å¤±æ•—"
    print(f"âœ… å¹³å‡è¶³è¨ˆç®—: {len(ha_result)} rows")
    
    # OsMAè¨ˆç®—ãƒ†ã‚¹ãƒˆ
    osma_result = indicators.calculate_osma(sample_data)
    assert 'osma' in osma_result.columns, "OsMAè¨ˆç®—å¤±æ•—"
    print(f"âœ… OsMAè¨ˆç®—: {len(osma_result)} rows")
    
    # ç§»å‹•å¹³å‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ
    ma_result = indicators.calculate_moving_averages(sample_data)
    assert 'ma_10' in ma_result.columns, "ç§»å‹•å¹³å‡è¨ˆç®—å¤±æ•—"
    print(f"âœ… ç§»å‹•å¹³å‡è¨ˆç®—: {len(ma_result)} rows")
    
    # ãƒ¬ãƒ³ã‚¸å¢ƒç•Œè¨ˆç®—ãƒ†ã‚¹ãƒˆ
    range_result = indicators.calculate_range_boundaries(sample_data)
    assert 'range_high' in range_result.columns, "ãƒ¬ãƒ³ã‚¸è¨ˆç®—å¤±æ•—"
    print(f"âœ… ãƒ¬ãƒ³ã‚¸å¢ƒç•Œè¨ˆç®—: {len(range_result)} rows")
    
    # åŒé€†åˆ¤å®šåŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
    dokyaku_result = indicators.calculate_dokyaku_base(sample_data)
    assert 'deviation_direction' in dokyaku_result.columns, "åŒé€†åŸºç¤è¨ˆç®—å¤±æ•—"
    print(f"âœ… åŒé€†åˆ¤å®šåŸºç¤è¨ˆç®—: {len(dokyaku_result)} rows")
    
    # è¡Œå¸°åˆ¤å®šåŸºç¤ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
    ikikaeri_result = indicators.calculate_ikikaeri_base(sample_data, ha_result)
    assert 'ikikaeri_pattern' in ikikaeri_result.columns, "è¡Œå¸°åŸºç¤è¨ˆç®—å¤±æ•—"
    print(f"âœ… è¡Œå¸°åˆ¤å®šåŸºç¤è¨ˆç®—: {len(ikikaeri_result)} rows")
    
    print("âœ… åŸºæœ¬æŒ‡æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆå®Œäº†\n")
    return True

def test_database_operations():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    db = DatabaseManager("./data/test_integration.db")
    
    # ã‚µãƒ³ãƒ—ãƒ«ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    test_df = pd.DataFrame({
        'open': [150.0, 150.1, 150.2],
        'high': [150.1, 150.3, 150.4],
        'low': [149.9, 150.0, 150.1],
        'close': [150.1, 150.2, 150.3],
        'volume': [1000, 1100, 1200]
    }, index=pd.date_range('2024-01-01 00:00', periods=3, freq='1min'))
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ
    db.save_price_data("USD_JPY", "M1", test_df)
    
    # èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    loaded_df = db.load_price_data("USD_JPY", "M1")
    assert len(loaded_df) == 3, "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿å¤±æ•—"
    print("âœ… ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿æˆåŠŸ")
    
    # å¹³å‡è¶³ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ
    ha_df = test_df.copy()
    ha_df['ha_open'] = 150.0
    ha_df['ha_high'] = 150.4
    ha_df['ha_low'] = 149.9
    ha_df['ha_close'] = 150.3
    ha_df['ha_direction'] = 1
    
    db.save_heikin_ashi_data("USD_JPY", "M1", ha_df)
    print("âœ… å¹³å‡è¶³ãƒ‡ãƒ¼ã‚¿ä¿å­˜æˆåŠŸ")
    
    # ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¿¡å·ä¿å­˜ãƒ†ã‚¹ãƒˆ
    signals = {
        'dokyaku': 1,
        'ikikaeri': 1,
        'momi': 0,
        'overshoot': 0,
        'overall': 1
    }
    signal_id = db.save_operation_signal("USD_JPY", "M1", datetime.now(), signals, 0.75)
    assert signal_id > 0, "ä¿¡å·ä¿å­˜å¤±æ•—"
    print("âœ… ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¿¡å·ä¿å­˜æˆåŠŸ")
    
    # çµ±è¨ˆæƒ…å ±ç¢ºèª
    stats = db.get_database_stats()
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ: {stats}")
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    os.remove("./data/test_integration.db")
    print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ†ã‚¹ãƒˆå®Œäº†\n")
    return True

def test_operation_logic():
    """ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§  ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    engine = OperationLogicEngine()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    test_data = {
        'dokyaku_data': {
            'mhih_direction': Direction.UP,
            'mjih_direction': Direction.UP,
            'mmhmh_direction': Direction.UP,
            'mmjmh_direction': Direction.DOWN,
            'mh_confirm_direction': Direction.UP,
            'is_transition_bar': False
        },
        'ikikaeri_data': {
            'current_heikin_direction': Direction.UP,
            'previous_heikin_direction': Direction.UP,
            'high_low_update': True,
            'base_line_position': 150.50,
            'current_price': 150.75
        },
        'momi_data': {
            'range_width': 5.0,  # ã‚‚ã¿ã§ã¯ãªã„
            'os_remaining': 3.0,
            'current_timeframe_conversion': 1.0,
            'breakout_direction': Direction.UP,
            'previous_overshoot': Direction.DOWN
        },
        'timeframe_data': {
            'timeframe_directions': {
                TimeFrame.M15: Direction.UP,
                TimeFrame.M5: Direction.UP
            },
            'transition_timings': {
                TimeFrame.M15: False,
                TimeFrame.M5: True
            }
        },
        'previous_heikin_valid': True,
        'period_alignment': True,
        'overshoot_established': True,
        'minute_alignment': False,
        'opff_previous_alignment': False,
        'timeframe_connection_point': False
    }
    
    # åˆ¤å®šå®Ÿè¡Œ
    result = engine.make_decision(test_data)
    
    assert 'direction' in result, "åˆ¤å®šçµæœã«æ–¹å‘ãŒãªã„"
    assert 'confidence' in result, "åˆ¤å®šçµæœã«ä¿¡é ¼åº¦ãŒãªã„"
    assert 'entry_signal' in result, "åˆ¤å®šçµæœã«ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¿¡å·ãŒãªã„"
    
    print(f"âœ… åˆ¤å®šæ–¹å‘: {result['direction']}")
    print(f"âœ… ä¿¡é ¼åº¦: {result['confidence']:.3f}")
    print(f"âœ… ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¿¡å·: {result['entry_signal']}")
    print(f"âœ… ã‚¨ã‚°ã‚¸ãƒƒãƒˆä¿¡å·: {result['exit_signal']}")
    
    # è©³ç´°çµæœç¢ºèª
    details = result['details']
    print("âœ… åˆ¤å®šè©³ç´°:")
    for system, (direction, confidence) in details.items():
        print(f"   {system}: {direction} (ä¿¡é ¼åº¦: {confidence:.3f})")
    
    print("âœ… ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†\n")
    return True

def test_performance_tracking():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    tracker = PerformanceTracker()
    
    # å„æ“ä½œã®å®Ÿè¡Œæ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    tracker.measure_performance('å…¨ä½“', 15.5)  # ç›®æ¨™19msä»¥ä¸‹
    tracker.measure_performance('ã‚‚ã¿', 68.2)  # ç›®æ¨™77msä»¥ä¸‹
    tracker.measure_performance('OPåˆ†å²', 95.1)  # ç›®æ¨™101.3msä»¥ä¸‹
    tracker.measure_performance('ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆ', 520.3)  # ç›®æ¨™550.6msä»¥ä¸‹
    
    # ã‚µãƒãƒªãƒ¼å–å¾—
    summary = tracker.get_performance_summary()
    print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼:")
    for operation, stats in summary.items():
        print(f"   {operation}: å¹³å‡ {stats['avg']:.1f}ms (ç›®æ¨™: {stats['target']}ms)")
    
    print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ãƒ†ã‚¹ãƒˆå®Œäº†\n")
    return True

def test_multi_timeframe_integration():
    """ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆã®ãƒ†ã‚¹ãƒˆ"""
    print("â° ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    indicators = BaseIndicators()
    
    # è¤‡æ•°æ™‚é–“è¶³ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    timeframes = ['M1', 'M5', 'M15', 'M30']
    multi_data = {}
    
    for tf in timeframes:
        if tf == 'M1':
            periods = 100
            freq = '1min'
        elif tf == 'M5':
            periods = 50
            freq = '5min'
        elif tf == 'M15':
            periods = 20
            freq = '15min'
        else:  # M30
            periods = 10
            freq = '30min'
        
        dates = pd.date_range('2024-01-01', periods=periods, freq=freq)
        df = pd.DataFrame({
            'open': np.random.randn(periods).cumsum() + 150,
            'high': np.random.randn(periods).cumsum() + 151,
            'low': np.random.randn(periods).cumsum() + 149,
            'close': np.random.randn(periods).cumsum() + 150
        }, index=dates)
        
        multi_data[tf] = df
    
    # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆè¨ˆç®—
    integrated_data = indicators.calculate_multi_timeframe_data(multi_data)
    
    assert len(integrated_data) == 4, "çµ±åˆãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“è¶³æ•°ãŒä¸æ­£"
    
    for tf, df in integrated_data.items():
        assert 'ha_direction' in df.columns, f"{tf}ã®å¹³å‡è¶³è¨ˆç®—å¤±æ•—"
        assert 'osma' in df.columns, f"{tf}ã®OsMAè¨ˆç®—å¤±æ•—"
        assert 'ikikaeri_pattern' in df.columns, f"{tf}ã®è¡Œå¸°ãƒ‘ã‚¿ãƒ¼ãƒ³è¨ˆç®—å¤±æ•—"
        print(f"âœ… {tf}çµ±åˆãƒ‡ãƒ¼ã‚¿: {len(df)} rows")
    
    print("âœ… ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†\n")
    return True

def main():
    """çµ±åˆãƒ†ã‚¹ãƒˆãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ FXã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹\n")
    print("=" * 50)
    
    test_results = []
    
    try:
        # å„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        test_results.append(("åŸºæœ¬æŒ‡æ¨™è¨ˆç®—", test_indicators_calculation()))
        test_results.append(("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ", test_database_operations()))
        test_results.append(("ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯", test_operation_logic()))
        test_results.append(("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡", test_performance_tracking()))
        test_results.append(("ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆ", test_multi_timeframe_integration()))
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("=" * 50)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
    
    all_passed = True
    for test_name, result in test_results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"   {test_name}: {status}")
        if not result:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼Week 1 Day 1-2ã®å®Ÿè£…å®Œäº†ç¢ºèª")
        print("ğŸ“‹ Week 1 Day 3-4: ãƒ¡ãƒ¢ãƒ•ã‚¡ã‚¤ãƒ«å¾¹åº•åˆ†æã®æº–å‚™å®Œäº†")
    else:
        print("\nâš ï¸  ä¸€éƒ¨ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)