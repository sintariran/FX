#!/usr/bin/env python3
"""
PKGé–¢æ•°ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ - çœŸã®é–¢æ•°å‹DAGã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å®Ÿè£…

ãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡æ‘˜äº‹é …ã¸ã®å¯¾å¿œ:
- æ‰‹å‹•çµ±åˆã‹ã‚‰é–¢æ•°å‹DAGå‡¦ç†ã¸ã®ç§»è¡Œ
- PKGFunctionManagerã«ã‚ˆã‚‹è‡ªå‹•ä¾å­˜é–¢ä¿‚è§£æ±º
- éšå±¤ãƒã‚§ãƒƒã‚¯ã¨è‡ªå‹•å®Ÿè¡Œé †åºæ±ºå®š
- ãƒ¡ãƒ¢ãƒ­ã‚¸ãƒƒã‚¯ã®DAGåŒ–

è¨­è¨ˆåŸå‰‡:
1. å„åˆ¤å®šã‚¯ãƒ©ã‚¹ã‚’PKGFunctionã¨ã—ã¦ç™»éŒ²
2. ä¾å­˜é–¢ä¿‚ã‚’è‡ªå‹•è§£æ±º
3. éšå±¤ä¸€è²«æ€§ã‚’æ¤œè¨¼
4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
"""

import logging
from typing import Dict, List, Optional, Any, Set, Tuple, Union
from dataclasses import dataclass, field
from collections import defaultdict, deque
from enum import Enum
import time
from datetime import datetime

# PKGåŸºæœ¬è¦ç´ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from core_pkg_functions import (
    BasePKGFunction, PKGId, TimeFrame, Currency, Period,
    MarketData, OperationSignal,
    DokyakuFunction, IkikaerikFunction, PKGFunctionFactory
)

class FunctionLevel(Enum):
    """PKGé–¢æ•°ã®éšå±¤ãƒ¬ãƒ™ãƒ«"""
    RAW_DATA = 0      # Layer 0: ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆAA001-329, BA001-BB999, CA001-142ï¼‰
    INDICATORS = 1    # Layer 1: åŸºæœ¬æŒ‡æ¨™ï¼ˆå¹³å‡è¶³ã€ç§»å‹•å¹³å‡ã€OsMAç­‰ï¼‰
    OPERATIONS = 2    # Layer 2: åŸºæœ¬æ¼”ç®—ï¼ˆZ, SL, OR, AND, CO, SGç­‰ï¼‰
    JUDGMENTS = 3     # Layer 3: åˆ¤å®šé–¢æ•°ï¼ˆåŒé€†ã€è¡Œå¸°ã€ã‚‚ã¿/OSç­‰ï¼‰
    INTEGRATION = 4   # Layer 4: çµ±åˆåˆ¤æ–­ï¼ˆæ™‚é–“çµåˆã€ç·åˆä¿¡å·ï¼‰

@dataclass
class PKGNodeDefinition:
    """PKGé–¢æ•°ãƒãƒ¼ãƒ‰ã®å®šç¾©"""
    pkg_id: PKGId
    function_type: str
    function_instance: Optional[BasePKGFunction] = None
    input_dependencies: List[PKGId] = field(default_factory=list)
    layer: int = 0
    cached_result: Optional[Any] = None
    last_evaluation_time: Optional[datetime] = None
    evaluation_count: int = 0
    
    def __str__(self) -> str:
        return f"PKGNode({self.pkg_id}, {self.function_type}, L{self.layer})"

class PKGFunctionManager:
    """
    PKGé–¢æ•°ã®å®Œå…¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    
    æ©Ÿèƒ½:
    - DAGæ§‹ç¯‰ã¨ä¾å­˜é–¢ä¿‚è§£æ±º
    - éšå±¤ä¸€è²«æ€§æ¤œè¨¼
    - è‡ªå‹•å®Ÿè¡Œé †åºæ±ºå®š
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # PKGé–¢æ•°ãƒ¬ã‚¸ã‚¹ãƒˆãƒª
        self.nodes: Dict[str, PKGNodeDefinition] = {}  # str(PKGId) -> PKGNodeDefinition
        self.raw_data_store: Dict[str, Any] = {}
        
        # DAGç®¡ç†
        self.execution_order: List[str] = []
        self.layer_groups: Dict[int, List[str]] = defaultdict(list)
        
        # PKGé–¢æ•°ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼
        self.function_factory = PKGFunctionFactory()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
        self.performance_stats = {
            'total_evaluations': 0,
            'cache_hits': 0,
            'total_execution_time': 0.0,
            'layer_execution_times': defaultdict(float)
        }
        
        self.logger.info("PKGFunctionManager initialized")
    
    def register_raw_data_symbol(self, symbol: str, timeframe: TimeFrame,
                                period: Period, currency: Currency, 
                                value: Any) -> PKGId:
        """
        ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ³ãƒœãƒ«ã‚’PKG IDä½“ç³»ã§ç™»éŒ²
        
        ä¾‹: AA001 â†’ PKGId(M15, COMMON, USDJPY, 0, AA001)
        """
        # ç”Ÿãƒ‡ãƒ¼ã‚¿ã®PKG IDç”Ÿæˆ
        sequence = self._symbol_to_sequence(symbol)
        pkg_id = PKGId(timeframe, period, currency, 0, sequence)
        pkg_id_str = str(pkg_id)
        
        # ãƒãƒ¼ãƒ‰å®šç¾©ä½œæˆ
        node = PKGNodeDefinition(
            pkg_id=pkg_id,
            function_type="RAW_DATA",
            layer=0,
            cached_result=value,
            last_evaluation_time=datetime.now()
        )
        
        self.nodes[pkg_id_str] = node
        self.raw_data_store[pkg_id_str] = value
        self.layer_groups[0].append(pkg_id_str)
        
        self.logger.debug(f"ç”Ÿãƒ‡ãƒ¼ã‚¿ç™»éŒ²: {pkg_id_str} = {value}")
        return pkg_id
    
    def register_pkg_function(self, pkg_id: PKGId, function_type: str,
                            input_dependencies: List[PKGId], 
                            **function_params) -> None:
        """
        PKGé–¢æ•°ã‚’DAGã«ç™»éŒ²
        
        Args:
            pkg_id: PKGé–¢æ•°ã®ID
            function_type: é–¢æ•°ã‚¿ã‚¤ãƒ—ï¼ˆ'Dokyaku', 'Ikikaeri', 'Z', 'SL'ç­‰ï¼‰
            input_dependencies: ä¾å­˜ã™ã‚‹å…¥åŠ›PKG IDã®ãƒªã‚¹ãƒˆ
            **function_params: é–¢æ•°å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        pkg_id_str = str(pkg_id)
        
        # éšå±¤ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        if not self._validate_layer_consistency(pkg_id, input_dependencies):
            raise ValueError(f"éšå±¤ä¸€è²«æ€§é•å: {pkg_id_str}")
        
        # é–¢æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        try:
            function_instance = self.function_factory.create_function(
                function_type, pkg_id
            )
            if hasattr(function_instance, 'configure'):
                function_instance.configure(**function_params)
        except Exception as e:
            self.logger.error(f"é–¢æ•°ä½œæˆã‚¨ãƒ©ãƒ¼ {pkg_id_str}: {e}")
            raise
        
        # ãƒãƒ¼ãƒ‰å®šç¾©ä½œæˆ
        node = PKGNodeDefinition(
            pkg_id=pkg_id,
            function_type=function_type,
            function_instance=function_instance,
            input_dependencies=input_dependencies,
            layer=pkg_id.layer
        )
        
        self.nodes[pkg_id_str] = node
        self.layer_groups[pkg_id.layer].append(pkg_id_str)
        
        # å®Ÿè¡Œé †åºã‚’ç„¡åŠ¹åŒ–ï¼ˆå†è¨ˆç®—ãŒå¿…è¦ï¼‰
        self.execution_order = []
        
        self.logger.info(f"PKGé–¢æ•°ç™»éŒ²: {pkg_id_str} = {function_type}")
        self.logger.debug(f"  ä¾å­˜é–¢ä¿‚: {[str(dep) for dep in input_dependencies]}")
    
    def register_memo_logic_as_dag(self, currency: Currency = Currency.USDJPY,
                                  timeframe: TimeFrame = TimeFrame.M15) -> None:
        """
        ãƒ¡ãƒ¢ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ4ã‚³ã‚¢æ¦‚å¿µï¼‰ã‚’DAGæ§‹é€ ã§ç™»éŒ²
        
        ã“ã‚ŒãŒãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡æ‘˜ã®æ ¸å¿ƒ: æ‰‹å‹•çµ±åˆâ†’DAGåŒ–
        """
        self.logger.info("ãƒ¡ãƒ¢ãƒ­ã‚¸ãƒƒã‚¯ã®DAGåŒ–ã‚’é–‹å§‹")
        
        # ãƒ€ãƒŸãƒ¼ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ï¼ˆå®Ÿéš›ã¯å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ï¼‰
        base_data_ids = []
        for i, symbol in enumerate(['AA001', 'AA002', 'BB001', 'CA001']):
            raw_id = self.register_raw_data_symbol(
                symbol, timeframe, Period.COMMON, currency, 0.0
            )
            base_data_ids.append(raw_id)
        
        # Layer 3: åˆ¤å®šé–¢æ•°ç¾¤ã‚’DAGåŒ–
        
        # åŒé€†åˆ¤å®šé–¢æ•°
        dokyaku_id = PKGId(timeframe, Period.COMMON, currency, 3, 1)
        self.register_pkg_function(
            dokyaku_id, 
            'Dokyaku',
            base_data_ids[:2]  # AA001, AA002ã«ä¾å­˜
        )
        
        # è¡Œå¸°åˆ¤å®šé–¢æ•°
        ikikaeri_id = PKGId(timeframe, Period.COMMON, currency, 3, 2)
        self.register_pkg_function(
            ikikaeri_id,
            'Ikikaeri', 
            base_data_ids[1:3]  # AA002, BB001ã«ä¾å­˜
        )
        
        # ã‚‚ã¿ãƒ»ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆåˆ¤å®šé–¢æ•°
        momi_os_id = PKGId(timeframe, Period.COMMON, currency, 3, 3)
        self.register_pkg_function(
            momi_os_id,
            'MomiOvershoot',
            base_data_ids[2:]  # BB001, CA001ã«ä¾å­˜
        )
        
        # Layer 4: çµ±åˆåˆ¤æ–­é–¢æ•°
        integration_id = PKGId(timeframe, Period.COMMON, currency, 4, 1)
        self.register_pkg_function(
            integration_id,
            'SignalIntegration',
            [dokyaku_id, ikikaeri_id, momi_os_id]  # Layer3ã®çµæœã‚’çµ±åˆ
        )
        
        self.logger.info(f"ãƒ¡ãƒ¢ãƒ­ã‚¸ãƒƒã‚¯DAGåŒ–å®Œäº†: {len(self.nodes)}ãƒãƒ¼ãƒ‰")
    
    def evaluate_dag(self, target_ids: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        DAGå…¨ä½“ã‚’è©•ä¾¡ã—ã¦çµæœã‚’è¿”ã™
        
        ã“ã‚ŒãŒãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡æ‘˜ã¸ã®å›ç­”: è‡ªå‹•DAGå‡¦ç†
        """
        start_time = time.time()
        
        # å®Ÿè¡Œé †åºã®æ±ºå®šï¼ˆãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã‚½ãƒ¼ãƒˆï¼‰
        if not self.execution_order:
            self.execution_order = self._compute_execution_order()
        
        results = {}
        layer_times = defaultdict(float)
        
        # éšå±¤é †ã«å®Ÿè¡Œ
        for pkg_id_str in self.execution_order:
            layer_start = time.time()
            node = self.nodes[pkg_id_str]
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            if self._is_cache_valid(node):
                results[pkg_id_str] = node.cached_result
                self.performance_stats['cache_hits'] += 1
                continue
            
            # é–¢æ•°å®Ÿè¡Œ
            try:
                if node.function_type == "RAW_DATA":
                    # ç”Ÿãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿
                    result = node.cached_result
                else:
                    # ä¾å­˜ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
                    input_data = self._collect_input_data(node, results)
                    
                    # PKGé–¢æ•°ã‚’å®Ÿè¡Œ
                    result = node.function_instance.execute(input_data)
                    
                    # çµ±è¨ˆæ›´æ–°
                    node.evaluation_count += 1
                    node.last_evaluation_time = datetime.now()
                
                # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                node.cached_result = result
                results[pkg_id_str] = result
                
                layer_time = time.time() - layer_start
                layer_times[node.layer] += layer_time
                
                self.logger.debug(f"è©•ä¾¡å®Œäº†: {pkg_id_str} = {result} ({layer_time*1000:.2f}ms)")
                
            except Exception as e:
                self.logger.error(f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼ {pkg_id_str}: {e}")
                results[pkg_id_str] = None
        
        # æ€§èƒ½çµ±è¨ˆæ›´æ–°
        total_time = time.time() - start_time
        self.performance_stats['total_evaluations'] += 1
        self.performance_stats['total_execution_time'] += total_time
        for layer, layer_time in layer_times.items():
            self.performance_stats['layer_execution_times'][layer] += layer_time
        
        self.logger.info(f"DAGè©•ä¾¡å®Œäº†: {total_time*1000:.2f}ms, {len(results)}ãƒãƒ¼ãƒ‰")
        
        # æŒ‡å®šã•ã‚ŒãŸIDã®çµæœã®ã¿è¿”ã™
        if target_ids:
            return {pkg_id: results.get(pkg_id) for pkg_id in target_ids 
                   if pkg_id in results}
        
        return results
    
    def get_integrated_trading_signal(self, market_data: Dict[str, List[MarketData]],
                                    currency: Currency = Currency.USDJPY) -> Dict[str, Any]:
        """
        çµ±åˆå–å¼•ä¿¡å·ã®å–å¾—
        
        ã“ã‚ŒãŒæ—§OperationLogicEngineã®ä»£æ›¿: DAGè‡ªå‹•å‡¦ç†
        """
        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’PKGç”Ÿãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ç™»éŒ²
        self._update_raw_data_from_market(market_data, currency)
        
        # DAGã‚’è©•ä¾¡
        results = self.evaluate_dag()
        
        # Layer4ã®çµ±åˆåˆ¤æ–­çµæœã‚’å–å¾—
        integration_key = None
        for pkg_id_str, node in self.nodes.items():
            if node.layer == 4 and node.function_type == 'SignalIntegration':
                integration_key = pkg_id_str
                break
        
        if integration_key and integration_key in results:
            integration_result = results[integration_key]
            
            return {
                'overall_direction': self._extract_direction(integration_result),
                'confidence': self._extract_confidence(integration_result),
                'dokyaku_signal': results.get(self._find_function_id('Dokyaku')),
                'ikikaeri_signal': results.get(self._find_function_id('Ikikaeri')),
                'momi_overshoot_signal': results.get(self._find_function_id('MomiOvershoot')),
                'raw_results': results
            }
        else:
            self.logger.warning("çµ±åˆåˆ¤æ–­çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {'overall_direction': 0, 'confidence': 0.0}
    
    def validate_hierarchy_consistency(self) -> Tuple[bool, List[str]]:
        """
        éšå±¤ä¸€è²«æ€§ã®æ¤œè¨¼
        
        ä¸Šä½å±¤ãŒä¸‹ä½å±¤ã®ã¿ã‚’å‚ç…§ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        """
        violations = []
        
        for pkg_id_str, node in self.nodes.items():
            for dep_id in node.input_dependencies:
                dep_str = str(dep_id)
                if dep_str in self.nodes:
                    dep_node = self.nodes[dep_str]
                    if dep_node.layer >= node.layer:
                        violations.append(
                            f"{pkg_id_str}(L{node.layer}) ãŒ "
                            f"{dep_str}(L{dep_node.layer}) ã«ä¾å­˜"
                        )
                else:
                    violations.append(f"æœªç™»éŒ²ä¾å­˜: {pkg_id_str} -> {dep_str}")
        
        is_valid = len(violations) == 0
        
        if is_valid:
            self.logger.info("éšå±¤ä¸€è²«æ€§æ¤œè¨¼: OK")
        else:
            self.logger.error(f"éšå±¤ä¸€è²«æ€§é•å: {len(violations)}ä»¶")
            for violation in violations:
                self.logger.error(f"  - {violation}")
        
        return is_valid, violations
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—"""
        total_evals = self.performance_stats['total_evaluations']
        if total_evals == 0:
            return {'message': 'å®Ÿè¡Œå±¥æ­´ãªã—'}
        
        avg_time = self.performance_stats['total_execution_time'] / total_evals
        cache_hit_rate = self.performance_stats['cache_hits'] / total_evals * 100
        
        return {
            'total_evaluations': total_evals,
            'average_execution_time_ms': avg_time * 1000,
            'cache_hit_rate_percent': cache_hit_rate,
            'layer_performance': {
                f"Layer_{layer}": time_ms * 1000 / total_evals 
                for layer, time_ms in self.performance_stats['layer_execution_times'].items()
            },
            'registered_functions': len(self.nodes),
            'layers_used': sorted(self.layer_groups.keys())
        }
    
    def visualize_dag_structure(self) -> str:
        """DAGæ§‹é€ ã®å¯è¦–åŒ–"""
        lines = ["PKGé–¢æ•°å‹DAGæ§‹é€ :", "=" * 50]
        
        for layer in sorted(self.layer_groups.keys()):
            layer_name = FunctionLevel(layer).name if layer < 5 else f"CUSTOM_L{layer}"
            lines.append(f"\n{layer_name} (Layer {layer}):")
            
            nodes = self.layer_groups[layer]
            for pkg_id_str in sorted(nodes):
                node = self.nodes[pkg_id_str]
                if node.function_type == "RAW_DATA":
                    lines.append(f"  ğŸ“Š {pkg_id_str} = ç”Ÿãƒ‡ãƒ¼ã‚¿")
                else:
                    deps = [str(dep) for dep in node.input_dependencies[:2]]
                    if len(node.input_dependencies) > 2:
                        deps.append("...")
                    dep_str = ", ".join(deps) if deps else "ãªã—"
                    lines.append(f"  ğŸ”§ {pkg_id_str} = {node.function_type}({dep_str})")
        
        lines.append(f"\nå®Ÿè¡Œé †åº: {len(self.execution_order)}ãƒãƒ¼ãƒ‰")
        lines.append("=" * 50)
        
        return "\n".join(lines)
    
    # ======== ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ ========
    
    def _symbol_to_sequence(self, symbol: str) -> int:
        """ã‚·ãƒ³ãƒœãƒ«ã‚’ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã«å¤‰æ›"""
        # AA001 â†’ 1, BB123 â†’ 123 ç­‰ã®ç°¡æ˜“ãƒãƒƒãƒ”ãƒ³ã‚°
        if symbol.startswith(('AA', 'BA', 'CA')):
            return int(symbol[2:])
        return hash(symbol) % 10000
    
    def _validate_layer_consistency(self, pkg_id: PKGId, dependencies: List[PKGId]) -> bool:
        """éšå±¤ä¸€è²«æ€§ã®äº‹å‰ãƒã‚§ãƒƒã‚¯"""
        for dep in dependencies:
            if dep.layer >= pkg_id.layer:
                return False
        return True
    
    def _compute_execution_order(self) -> List[str]:
        """ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã‚½ãƒ¼ãƒˆã§å®Ÿè¡Œé †åºã‚’æ±ºå®š"""
        in_degree = defaultdict(int)
        adjacency = defaultdict(list)
        
        # ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        for pkg_id_str, node in self.nodes.items():
            for dep in node.input_dependencies:
                dep_str = str(dep)
                if dep_str in self.nodes:
                    adjacency[dep_str].append(pkg_id_str)
                    in_degree[pkg_id_str] += 1
        
        # å…¥æ¬¡æ•°0ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰é–‹å§‹
        queue = deque([pkg_id for pkg_id in self.nodes if in_degree[pkg_id] == 0])
        result = []
        
        while queue:
            current = queue.popleft()
            result.append(current)
            
            for neighbor in adjacency[current]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        # å¾ªç’°ä¾å­˜ãƒã‚§ãƒƒã‚¯
        if len(result) != len(self.nodes):
            remaining = set(self.nodes.keys()) - set(result)
            raise ValueError(f"å¾ªç’°ä¾å­˜æ¤œå‡º: {remaining}")
        
        return result
    
    def _is_cache_valid(self, node: PKGNodeDefinition) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯"""
        if node.cached_result is None:
            return False
        if node.function_type == "RAW_DATA":
            return True  # ç”Ÿãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«æœ‰åŠ¹
        # å®Ÿè£…ã‚’ç°¡ç´ åŒ–: å¸¸ã«å†è©•ä¾¡
        return False
    
    def _collect_input_data(self, node: PKGNodeDefinition, results: Dict[str, Any]) -> Dict[str, Any]:
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®åé›†"""
        input_data = {}
        
        # åŸºæœ¬çš„ãªå…¥åŠ›åé›†
        inputs = []
        for dep in node.input_dependencies:
            dep_str = str(dep)
            if dep_str in results:
                inputs.append(results[dep_str])
        
        # é–¢æ•°ã‚¿ã‚¤ãƒ—åˆ¥ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼
        if node.function_type in ['Dokyaku', 'Ikikaeri', 'MomiOvershoot']:
            # ãƒ¡ãƒ¢ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ã¯ market_data å½¢å¼
            input_data['market_data'] = inputs if inputs else []
        else:
            # ä¸€èˆ¬çš„ãªPKGé–¢æ•°ã¯ inputs å½¢å¼
            input_data['inputs'] = inputs
        
        return input_data
    
    def _update_raw_data_from_market(self, market_data: Dict[str, List[MarketData]],
                                   currency: Currency):
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰PKGç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        # å®Ÿè£…ç°¡ç•¥åŒ–: M15ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
        m15_data = market_data.get('M15', [])
        if m15_data:
            current_bar = m15_data[-1]
            # ãƒ€ãƒŸãƒ¼æ›´æ–°
            for pkg_id_str in list(self.raw_data_store.keys()):
                self.raw_data_store[pkg_id_str] = current_bar.close
                self.nodes[pkg_id_str].cached_result = current_bar.close
    
    def _find_function_id(self, function_type: str) -> Optional[str]:
        """é–¢æ•°ã‚¿ã‚¤ãƒ—ã‹ã‚‰PKG IDã‚’æ¤œç´¢"""
        for pkg_id_str, node in self.nodes.items():
            if node.function_type == function_type:
                return pkg_id_str
        return None
    
    def _extract_direction(self, signal) -> int:
        """ä¿¡å·ã‹ã‚‰æ–¹å‘ã‚’æŠ½å‡º"""
        if isinstance(signal, OperationSignal):
            return signal.direction
        return 0
    
    def _extract_confidence(self, signal) -> float:
        """ä¿¡å·ã‹ã‚‰ä¿¡é ¼åº¦ã‚’æŠ½å‡º"""
        if isinstance(signal, OperationSignal):
            return signal.confidence
        return 0.0


# ä½¿ç”¨ä¾‹: æ—§æ‰‹å‹•çµ±åˆã®ç½®ãæ›ãˆ
def demo_pkg_function_manager():
    """PKGFunctionManagerã®ãƒ‡ãƒ¢"""
    logging.basicConfig(level=logging.INFO)
    
    manager = PKGFunctionManager()
    
    # ãƒ¡ãƒ¢ãƒ­ã‚¸ãƒƒã‚¯ã‚’DAGåŒ–
    manager.register_memo_logic_as_dag()
    
    # DAGæ§‹é€ ã‚’è¡¨ç¤º
    print(manager.visualize_dag_structure())
    
    # éšå±¤ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
    is_valid, violations = manager.validate_hierarchy_consistency()
    print(f"\néšå±¤ä¸€è²«æ€§: {'âœ“' if is_valid else 'âœ—'}")
    
    # ãƒ€ãƒŸãƒ¼å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
    dummy_market_data = {
        'M15': [MarketData(
            timestamp=datetime.now(),
            open=150.0, high=150.1, low=149.9, close=150.05,
            volume=1000, 
            heikin_ashi_close=150.02, heikin_ashi_open=149.98
        )]
    }
    
    # çµ±åˆå–å¼•ä¿¡å·ã‚’å–å¾—
    signal = manager.get_integrated_trading_signal(dummy_market_data)
    print(f"\nçµ±åˆå–å¼•ä¿¡å·: {signal}")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ
    perf_report = manager.get_performance_report()
    print(f"\nãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {perf_report}")

if __name__ == "__main__":
    demo_pkg_function_manager()