#!/usr/bin/env python3
"""
initial_setting_list_os.xlsxã‹ã‚‰PKGå®šç¾©ã‚’æŠ½å‡ºã—ã¦DAGã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
åŠ å·¥ã‚³ãƒ¼ãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰å®Ÿéš›ã®PKGé–¢æ•°å®šç¾©ã‚’èª­ã¿å–ã‚Šã€DAGã‚¨ãƒ³ã‚¸ãƒ³ã«ç™»éŒ²
"""

import os
import sys
import zipfile
import xml.etree.ElementTree as ET
from collections import defaultdict, OrderedDict
import re
import logging
from typing import Dict, List, Tuple, Optional, Set

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from dag_engine_v2 import DAGEngine
from raw_symbol_to_pkg import RawSymbolConverter

class ExcelPKGExtractor:
    """Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰PKGå®šç¾©ã‚’æŠ½å‡º"""
    
    def __init__(self, filepath: str):
        self.filepath = filepath
        self.logger = logging.getLogger(__name__)
        self.shared_strings = {}
        self.pkg_definitions = []
        self.raw_symbols = set()
        
    def extract_shared_strings(self, xlsx):
        """å…±æœ‰æ–‡å­—åˆ—ã‚’æŠ½å‡º"""
        if 'xl/sharedStrings.xml' not in xlsx.namelist():
            return {}
        
        strings_xml = xlsx.read('xl/sharedStrings.xml')
        root = ET.fromstring(strings_xml)
        
        ns = {'main': 'http://schemas.openxmlformats.org/spreadsheetml/2006/main'}
        string_items = root.findall('.//main:si', ns)
        
        string_map = {}
        for i, si in enumerate(string_items):
            t_elem = si.find('.//main:t', ns)
            if t_elem is not None:
                string_map[str(i)] = t_elem.text if t_elem.text else ""
        
        return string_map
    
    def parse_cell_value(self, cell, string_map):
        """ã‚»ãƒ«ã®å€¤ã‚’è§£æ"""
        ns = {'main': 'http://schemas.openxmlformats.org/spreadsheetml/2006/main'}
        
        cell_type = cell.get('t', 'n')
        v_elem = cell.find('main:v', ns)
        
        if v_elem is None:
            return None
        
        value = v_elem.text
        
        if cell_type == 's':  # æ–‡å­—åˆ—
            return string_map.get(value, value)
        elif cell_type == 'b':  # ãƒ–ãƒ¼ãƒ«
            return value == '1'
        else:  # æ•°å€¤
            try:
                if '.' in value:
                    return float(value)
                else:
                    return int(value)
            except:
                return value
    
    def extract_kaiko_code_sheet(self, xlsx):
        """åŠ å·¥ã‚³ãƒ¼ãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰PKGå®šç¾©ã‚’æŠ½å‡º"""
        # sheet2.xml = åŠ å·¥ã‚³ãƒ¼ãƒ‰ã‚·ãƒ¼ãƒˆ
        sheet_path = 'xl/worksheets/sheet2.xml'
        
        if sheet_path not in xlsx.namelist():
            self.logger.warning(f"ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {sheet_path}")
            return
        
        sheet_xml = xlsx.read(sheet_path)
        root = ET.fromstring(sheet_xml)
        
        ns = {'main': 'http://schemas.openxmlformats.org/spreadsheetml/2006/main'}
        rows = root.findall('.//main:row', ns)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†
        for row_idx, row in enumerate(rows[1:], start=2):
            cells = row.findall('main:c', ns)
            if len(cells) < 10:
                continue
                
            row_data = []
            for cell in cells[:15]:  # å¿…è¦ãªåˆ—ã ã‘å–å¾—
                value = self.parse_cell_value(cell, self.shared_strings)
                row_data.append(value)
            
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡Œã‚’ãƒ‘ãƒ¼ã‚¹
            if len(row_data) >= 10 and row_data[1]:  # NAME1ãŒå­˜åœ¨
                self.process_kaiko_row(row_data)
    
    def process_kaiko_row(self, row_data):
        """åŠ å·¥ã‚³ãƒ¼ãƒ‰è¡Œã‚’å‡¦ç†ã—ã¦PKGå®šç¾©ã‚’ä½œæˆ"""
        # ã‚«ãƒ©ãƒ å®šç¾©ï¼ˆExcelã‚·ãƒ¼ãƒˆã®æ§‹é€ ã«åŸºã¥ãï¼‰
        # 0: No., 1: NAME1, 2: NAME2, 3: ASI1, 4: ASI2, 5: Price
        # 6: TYPE, 7: THRESHOLD, 8: NUMBER, 9: KAIRI, 10: CODE
        
        name1 = row_data[1] if row_data[1] else None
        name2 = row_data[2] if row_data[2] else None
        asi1 = row_data[3] if row_data[3] else 3  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ15åˆ†è¶³
        asi2 = row_data[4] if row_data[4] else None
        price = row_data[5] if row_data[5] else 1
        func_type = row_data[6] if row_data[6] else None
        threshold = row_data[7] if row_data[7] else None
        number = row_data[8] if row_data[8] else None
        kairi = row_data[9] if row_data[9] else None
        
        if not name1 or not func_type:
            return
        
        # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ³ãƒœãƒ«ã‚’åé›†
        if isinstance(name1, str) and re.match(r'^[A-Z]{2}\d{1,3}$', name1):
            self.raw_symbols.add(name1)
        
        # KAIRIåˆ—ã‹ã‚‰ã‚·ãƒ³ãƒœãƒ«ã‚’æŠ½å‡º
        if kairi and isinstance(kairi, str):
            kairi_symbols = self.extract_symbols_from_kairi(kairi)
            self.raw_symbols.update(kairi_symbols)
            
            # PKGå®šç¾©ã‚’ä½œæˆ
            pkg_def = {
                'name': name1,
                'function_type': func_type,
                'input_symbols': kairi_symbols,
                'timeframe': asi1,
                'threshold': threshold,
                'group_number': number
            }
            self.pkg_definitions.append(pkg_def)
            
            self.logger.debug(f"PKGå®šç¾©: {name1} = {func_type}({kairi_symbols})")
    
    def extract_symbols_from_kairi(self, kairi_str: str) -> List[str]:
        """KAIRIæ–‡å­—åˆ—ã‹ã‚‰ã‚·ãƒ³ãƒœãƒ«ã‚’æŠ½å‡º"""
        symbols = []
        
        # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢åŒºåˆ‡ã‚Šã¾ãŸã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š
        parts = re.split(r'[_,\s]+', kairi_str)
        
        for part in parts:
            # ã‚·ãƒ³ãƒœãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒ
            if re.match(r'^[A-Z]{2}\d{1,3}$', part):
                symbols.append(part)
        
        return symbols
    
    def extract_all(self):
        """ã™ã¹ã¦ã®æƒ…å ±ã‚’æŠ½å‡º"""
        with zipfile.ZipFile(self.filepath, 'r') as xlsx:
            # å…±æœ‰æ–‡å­—åˆ—ã‚’èª­ã¿è¾¼ã¿
            self.shared_strings = self.extract_shared_strings(xlsx)
            
            # åŠ å·¥ã‚³ãƒ¼ãƒ‰ã‚·ãƒ¼ãƒˆã‚’è§£æ
            self.extract_kaiko_code_sheet(xlsx)
            
        return self.pkg_definitions, self.raw_symbols


class PKGGraphBuilder:
    """PKGå®šç¾©ã‹ã‚‰DAGã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
    
    def __init__(self):
        self.dag_engine = DAGEngine()
        self.symbol_converter = RawSymbolConverter()
        self.logger = logging.getLogger(__name__)
        self.registered_symbols = set()
        self.registered_pkgs = set()
        
    def build_from_definitions(self, pkg_definitions: List[Dict], 
                             raw_symbols: Set[str],
                             default_timeframe: int = 3,
                             default_currency: int = 1):
        """PKGå®šç¾©ã‹ã‚‰DAGã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
        
        # Step 1: ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ³ãƒœãƒ«ã‚’ç™»éŒ²
        self.logger.info(f"ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ³ãƒœãƒ«ç™»éŒ²: {len(raw_symbols)}å€‹")
        for symbol in raw_symbols:
            self.register_raw_symbol(symbol, default_timeframe, default_currency)
        
        # Step 2: PKGé–¢æ•°ã‚’éšå±¤é †ã«ç™»éŒ²
        self.logger.info(f"PKGé–¢æ•°ç™»éŒ²: {len(pkg_definitions)}å€‹")
        
        # éšå±¤ã‚’æ¨å®šï¼ˆå…¥åŠ›æ•°ãŒå°‘ãªã„ã‚‚ã®ã‹ã‚‰ï¼‰
        sorted_defs = sorted(pkg_definitions, 
                           key=lambda x: len(x.get('input_symbols', [])))
        
        for pkg_def in sorted_defs:
            self.register_pkg_function(pkg_def, default_currency)
        
        return self.dag_engine
    
    def register_raw_symbol(self, symbol: str, timeframe: int, currency: int):
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ³ãƒœãƒ«ã‚’DAGã«ç™»éŒ²"""
        if symbol in self.registered_symbols:
            return
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆï¼‰
        default_value = 100.0
        
        # PKG IDå½¢å¼ã§ç™»éŒ²
        self.dag_engine.register_raw_data(
            symbol=symbol,
            timeframe=timeframe,
            period=9,  # å…±é€š
            currency=currency,
            value=default_value
        )
        
        self.registered_symbols.add(symbol)
        self.logger.debug(f"ç”Ÿãƒ‡ãƒ¼ã‚¿ç™»éŒ²: {symbol} â†’ {timeframe}9{currency}^0-{symbol}")
    
    def register_pkg_function(self, pkg_def: Dict, currency: int):
        """PKGé–¢æ•°ã‚’DAGã«ç™»éŒ²"""
        name = pkg_def['name']
        func_type = pkg_def['function_type']
        input_symbols = pkg_def.get('input_symbols', [])
        timeframe = pkg_def.get('timeframe', 3)
        
        if not input_symbols:
            self.logger.warning(f"å…¥åŠ›ã‚·ãƒ³ãƒœãƒ«ãªã—: {name}")
            return
        
        # PKG IDã‚’ç”Ÿæˆï¼ˆéšå±¤ã‚’æ¨å®šï¼‰
        layer = self.estimate_layer(name)
        sequence = self.extract_sequence(name)
        pkg_id = f"{timeframe}9{currency}^{layer}-{sequence}"
        
        # å…¥åŠ›å‚ç…§ã‚’PKG IDå½¢å¼ã«å¤‰æ›
        input_refs = []
        for inp_symbol in input_symbols:
            if inp_symbol in self.registered_symbols:
                # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ³ãƒœãƒ«
                input_refs.append(f"{timeframe}9{currency}^0-{inp_symbol}")
            elif inp_symbol in self.registered_pkgs:
                # ä»–ã®PKGé–¢æ•°ï¼ˆç°¡ç•¥åŒ–ã®ãŸã‚åŒã˜éšå±¤ã¨ä»®å®šï¼‰
                inp_layer = self.estimate_layer(inp_symbol)
                inp_seq = self.extract_sequence(inp_symbol)
                input_refs.append(f"{timeframe}9{currency}^{inp_layer}-{inp_seq}")
        
        if not input_refs:
            self.logger.warning(f"æœ‰åŠ¹ãªå…¥åŠ›å‚ç…§ãªã—: {name}")
            return
        
        # é–¢æ•°ã‚¿ã‚¤ãƒ—ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
        mapped_func_type = self.map_function_type(func_type)
        
        # DAGã‚¨ãƒ³ã‚¸ãƒ³ã«ç™»éŒ²
        self.dag_engine.register_function(
            pkg_id=pkg_id,
            function_type=mapped_func_type,
            input_refs=input_refs
        )
        
        self.registered_pkgs.add(name)
        self.logger.debug(f"PKGé–¢æ•°ç™»éŒ²: {pkg_id} = {mapped_func_type}({input_refs[:2]}...)")
    
    def estimate_layer(self, name: str) -> int:
        """ã‚·ãƒ³ãƒœãƒ«åã‹ã‚‰éšå±¤ã‚’æ¨å®š"""
        # SAxx = Layer 1, SBxx = Layer 2, etc.
        if name.startswith('SA'):
            return 1
        elif name.startswith('SB'):
            return 2
        elif name.startswith('SC'):
            return 3
        elif name.startswith('SD'):
            return 4
        elif name.startswith('SE'):
            return 5
        elif name.startswith('SF'):
            return 6
        else:
            # CAxx, AAxxç­‰ã¯ç”Ÿãƒ‡ãƒ¼ã‚¿æ‰±ã„
            return 0
    
    def extract_sequence(self, name: str) -> str:
        """ã‚·ãƒ³ãƒœãƒ«åã‹ã‚‰é€£ç•ªã‚’æŠ½å‡º"""
        match = re.search(r'\d+', name)
        if match:
            return match.group()
        return name
    
    def map_function_type(self, excel_type: str) -> str:
        """Excelé–¢æ•°ã‚¿ã‚¤ãƒ—ã‚’PKGé–¢æ•°ã‚¿ã‚¤ãƒ—ã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
        type_map = {
            'Ratio': 'Z',      # æ¯”ç‡è¨ˆç®—
            'AbsIchi': 'Z',    # çµ¶å¯¾å€¤è·é›¢
            'Jita': 'SL',      # è‡ªé€šè²¨ä»–é€šè²¨é¸æŠ
            'SELECT': 'SL',    # é¸æŠ
            'COUNT': 'CO',     # ã‚«ã‚¦ãƒ³ãƒˆ
            'ROUND': 'RO',     # ä¸¸ã‚
            'MINUTE': 'MN',    # åˆ†å–å¾—
        }
        
        return type_map.get(excel_type, 'Z')  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Zé–¢æ•°


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logging.basicConfig(level=logging.INFO,
                       format='%(levelname)s: %(message)s')
    
    filepath = "/Users/ksato/Documents/GitHub/AI-Wolf/FX/initial_setting_list_os.xlsx"
    
    if not os.path.exists(filepath):
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
        return
    
    print("=" * 60)
    print("PKGã‚°ãƒ©ãƒ•æ§‹ç¯‰ - initial_setting_list_os.xlsx")
    print("=" * 60)
    
    # Step 1: Excelã‹ã‚‰å®šç¾©ã‚’æŠ½å‡º
    print("\nğŸ“Š Excelè§£æä¸­...")
    extractor = ExcelPKGExtractor(filepath)
    pkg_definitions, raw_symbols = extractor.extract_all()
    
    print(f"  æŠ½å‡ºå®Œäº†:")
    print(f"    ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ³ãƒœãƒ«: {len(raw_symbols)}å€‹")
    print(f"    PKGå®šç¾©: {len(pkg_definitions)}å€‹")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    if raw_symbols:
        print(f"    ç”Ÿãƒ‡ãƒ¼ã‚¿ä¾‹: {list(raw_symbols)[:5]}")
    if pkg_definitions:
        print(f"    PKGå®šç¾©ä¾‹: {pkg_definitions[0] if pkg_definitions else 'ãªã—'}")
    
    # Step 2: DAGã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
    print("\nğŸ”§ DAGã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­...")
    builder = PKGGraphBuilder()
    dag_engine = builder.build_from_definitions(pkg_definitions, raw_symbols)
    
    # Step 3: ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’è¡¨ç¤º
    print("\nğŸ“ˆ DAGã‚°ãƒ©ãƒ•æ§‹é€ :")
    print(dag_engine.visualize_graph())
    
    # Step 4: ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡ï¼ˆæœ€åˆã®5å€‹ã®PKGï¼‰
    if builder.registered_pkgs:
        print("\nğŸ¯ ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡:")
        sample_pkgs = list(builder.registered_pkgs)[:3]
        
        for pkg_name in sample_pkgs:
            layer = builder.estimate_layer(pkg_name)
            seq = builder.extract_sequence(pkg_name)
            pkg_id = f"391^{layer}-{seq}"
            
            try:
                results = dag_engine.evaluate([pkg_id])
                if pkg_id in results:
                    print(f"  {pkg_name} ({pkg_id}) = {results[pkg_id]}")
            except Exception as e:
                print(f"  {pkg_name}: è©•ä¾¡ã‚¨ãƒ©ãƒ¼ - {e}")
    
    print("\nâœ… ã‚°ãƒ©ãƒ•æ§‹ç¯‰å®Œäº†")


if __name__ == "__main__":
    main()